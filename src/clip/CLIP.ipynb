{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7kzX_A3eG31",
        "outputId": "60d3a26e-2cd3-45df-df21-620db8bb91d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
        "!pip install ftfy regex tqdm\n",
        "\n",
        "!pip install git+https://github.com/openai/CLIP.g"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUP9J6ZSgb5q",
        "outputId": "dd0515a6-4bef-41e0-f001-504aa24cb303"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Collecting git+https://github.com/openai/CLIP.g\n",
            "  Cloning https://github.com/openai/CLIP.g to /tmp/pip-req-build-3unq7kud\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.g /tmp/pip-req-build-3unq7kud\n",
            "  fatal: could not read Username for 'https://github.com': No such device or address\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/openai/CLIP.g\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-3unq7kud\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m \u001b[32mgit clone --\u001b[0m\u001b[32mfilter\u001b[0m\u001b[32m=\u001b[0m\u001b[32mblob\u001b[0m\u001b[32m:none --quiet \u001b[0m\u001b[4;32mhttps://github.com/openai/CLIP.g\u001b[0m\u001b[32m \u001b[0m\u001b[32m/tmp/\u001b[0m\u001b[32mpip-req-build-3unq7kud\u001b[0m did not run successfully.\n",
            "\u001b[31m│\u001b[0m exit code: \u001b[1;36m128\u001b[0m\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1d4v9MsYBdrpcOmup0CND75Y-Hexmo3-t\n",
        "!unzip -qq \"/content/FULL [Heineken Vietnam] Developer Resources-20240603T132806Z-001.zip\" -d \"/content/dataset\"\n",
        "!rm \"/content/FULL [Heineken Vietnam] Developer Resources-20240603T132806Z-001.zip\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4xDSrEVeqag",
        "outputId": "522b0659-3592-4c5b-b605-1f5099db9874"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1d4v9MsYBdrpcOmup0CND75Y-Hexmo3-t\n",
            "From (redirected): https://drive.google.com/uc?id=1d4v9MsYBdrpcOmup0CND75Y-Hexmo3-t&confirm=t&uuid=5c0e5659-fdc6-4109-9a24-236d4fcaa46e\n",
            "To: /content/FULL [Heineken Vietnam] Developer Resources-20240603T132806Z-001.zip\n",
            "100% 1.10G/1.10G [00:25<00:00, 43.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "blLW6N9dhPuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nrSBAXUkhPtN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "LWY1UxqOhQDT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2x39yWFCnILE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install open_clip_torch"
      ],
      "metadata": {
        "id": "ENALkX67g2xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import open_clip as clip\n",
        "from PIL import Image\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model, _, preprocess = clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k', device=device)\n",
        "model.eval()\n",
        "tokenizer = clip.get_tokenizer('ViT-B-32')\n",
        "context = [\"in the outdoor_venue\",\n",
        "\"in the indoor_venue\",\n",
        "\"in the bar or night_club\", \"in the restaurant\",\n",
        "\"in the store\",\n",
        "\"in the supermarket\"\n",
        "]\n",
        "\n",
        "text = tokenizer(context).to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "BmbvK-IufM3B"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = []\n",
        "\n",
        "dataset_path = \"/content/dataset/FULL [Heineken Vietnam] Developer Resources\"\n",
        "\n",
        "for filename in os.listdir(dataset_path):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.png'):  # Adjust file extensions as needed\n",
        "        image_path = os.path.join(dataset_path , filename)\n",
        "        raw_image = Image.open(image_path)\n",
        "        image = preprocess(raw_image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
        "            image_features = model.encode_image(image)\n",
        "            text_features = model.encode_text(text)\n",
        "            image_features /= image_features.norm(dim=-1, keepdim=True)\n",
        "            text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "            text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
        "            max_value, max_index = torch.max(text_probs, dim=1)\n",
        "            ct = context[max_index]\n",
        "\n",
        "            object = {\n",
        "                \"filename\": filename,\n",
        "                \"context\": ct,\n",
        "                \"text_probs\": max_value\n",
        "            }\n",
        "            results_list.append(object)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aozOtNqSjUOS",
        "outputId": "2b770d78-94d0-439b-c423-e6b667afe1e5"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/amp/autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n"
      ],
      "metadata": {
        "id": "BK-8U0bZi6HQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/Colab Notebooks/HACKHCMC2024/context_result.json', 'w') as json_file:\n",
        "    json.dump(copy, json_file, indent=4)"
      ],
      "metadata": {
        "id": "sBAZR48U4t5w"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(copy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgxbVBeR4_AD",
        "outputId": "04027967-67d1-4039-bb1d-966fcc3a0173"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1484"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "my4f3j2w5Wpk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}